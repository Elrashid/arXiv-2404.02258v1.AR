# Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models (Arabic Translation)
# مزيج الأعماق: تخصيص الحوسبة ديناميكياً في نماذج اللغة القائمة على المحولات
## Description
This repository contains the Arabic translation of the research paper "Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models." The translation aims to make the content more accessible to Arabic-speaking researchers and enthusiasts in the field of machine learning and NLP.

The translation was performed using [claude.ai](https://claude.ai).

## Original Paper
The original paper can be viewed and downloaded from [arXiv](https://arxiv.org/pdf/2404.02258v1.pdf).

## Translated Document
You can view and download the Arabic translated document from the following links:

- **View Online**: [GitHub Viewer](https://github.com/Elrashid/arXiv-2404.02258v1.AR/blob/main/arXiv-2404.02258v1.ar.pdf)
- **Direct Download**: [Download PDF](https://raw.githubusercontent.com/Elrashid/arXiv-2404.02258v1.AR/main/arXiv-2404.02258v1.ar.pdf)

## Usage
This translated document is provided for educational and research purposes. Please ensure to cite both the original work and mention this translation accordingly if you use it in your research or reference it in any scholarly work.

 
